# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/185jos3fP6VYbG51IVs0twTFuS2mtKHtk
"""

!pip install foolbox
import foolbox
import numpy as np
import torchvision.models as models
import matplotlib.pyplot as plt

model = models.resnet18(pretrained=True).eval()
preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)
fmodel = foolbox.models.PyTorchModel(model, bounds=(0, 1), num_classes=1000, preprocessing=preprocessing)

image, label = foolbox.utils.imagenet_example(data_format='channels_first')
image = image / 255 # because our model expects values in [0, 1]
print('original class', label) #-> 282
plt.figure()
plt.imshow(np.transpose(image, (1, 2, 0)))
plt.show()
print('predicted class', np.argmax(fmodel.forward_one(image))) #-> 282

#FGSM ATTACK
attack = foolbox.v1.attacks.FGSM(fmodel)
adversarial = attack(image, label)
plt.figure()
plt.imshow(np.transpose(adversarial, (1, 2, 0)))
plt.show()
print('adversarial class', np.argmax(fmodel.forward_one(adversarial)))

#DEEP FOOL
attack = foolbox.v1.attacks.DeepFoolAttack(fmodel)
adversarial = attack(image, label)
plt.figure()
plt.imshow(np.transpose(adversarial, (1, 2, 0)))
plt.show()
print('adversarial class', np.argmax(fmodel.forward_one(adversarial)))